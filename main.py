import os
import sys
from dotenv import load_dotenv
from crawlers.crawler_headway import baixar_oferta_csv
from crawlers.crawler_noticias import buscar_noticias
from process.trusted_headway import process_headway_from_s3

def run_headway():
    """Executa o fluxo completo do crawler de Headway."""
    print("ğŸš„ Iniciando crawler de Headway...")

    # VariÃ¡veis do .env
    URL = os.environ.get("URL")
    LOCAL_PATH = os.environ.get("LOCAL_PATH")
    S3_BUCKET = os.environ.get("S3_BUCKET")
    S3_KEY_PREFIX = os.environ.get("S3_KEY_PREFIX")

    if not all([URL, LOCAL_PATH, S3_BUCKET, S3_KEY_PREFIX]):
        raise RuntimeError("VariÃ¡veis de ambiente ausentes. Verifique o arquivo .env.")

    # 1ï¸âƒ£ Baixar CSV e enviar ao S3
    baixar_oferta_csv(URL, LOCAL_PATH, S3_BUCKET, S3_KEY_PREFIX)

    # âš™ï¸ (opcional) Determinar dinamicamente o nome do arquivo salvo
    # Exemplo fixo para pipeline:
    input_s3_path = f"s3://{S3_BUCKET}/raw/headway2025.csv"
    output_s3_path = f"s3://{S3_BUCKET}/trusted/headway_trusted.csv"

    # 2ï¸âƒ£ Processar o CSV direto do S3
    print("ğŸš€ Iniciando processamento do arquivo Headway...")
    process_headway_from_s3(input_s3_path, output_s3_path)
    print(f"âœ… Processamento concluÃ­do. Arquivo final disponÃ­vel em: {output_s3_path}\n")


def run_noticias():
    """Executa o crawler de notÃ­cias."""
    print("ğŸ—ï¸ Iniciando crawler de notÃ­cias do MetrÃ´...")

    query = "MetrÃ´ SÃ£o Paulo site:g1.globo.com"
    noticias = buscar_noticias(query)

    if not noticias:
        print("Nenhuma notÃ­cia encontrada.")
    else:
        print("\nğŸ—ï¸ Ãšltimas notÃ­cias sobre o MetrÃ´ de SÃ£o Paulo:\n")
        for noticia in noticias:
            print(f"ğŸ“° {noticia['titulo']}")
            print(f"ğŸ”— {noticia['link']}\n")

def main():
    load_dotenv()

    run_headway()
    # run_noticias()

if __name__ == "__main__":
    main()
